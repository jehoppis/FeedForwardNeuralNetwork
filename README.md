# FeedForwardNeuralNetwork

The file "FeedForwardNN.py" defines a feedforward neural network class (FFNN) with at least one hidden layer using only numpy. The class uses ReLu activation and He initialization (randomly sampled from a standard normal distribution, scaled by sqrt(2)/N, where N = number of noedes in the previous layer) for the weights. It includes methods to evaluate, train over the whole data set as one batch, and train over mini-batches (based on a percentage of the training data).

The file "NN Curve fitting.py" creates two examples of the class FFNN. The first example takes 100 points uniformly from the interval [-2, 2] as training input data, and uses the function f(x) = x(x-1)(x+1) to generate training output data. The network then trains on mini_batches of size 5 (5%). Graphs of the pre-trained network, post-trained network, and loss (mean square error) function are produced. The second example takes 360,000 points uniformly from the square [-3, 3] as training input data, and uses the function g(x,y) = (x-y)^2 - (1/3)x^3 to generate training output data. Then it trains on mini-batches of size 3,600 (1%), and graphs of the training data inputs and outputs, training data and networks outputs (post training), and the loss function are produced. 
